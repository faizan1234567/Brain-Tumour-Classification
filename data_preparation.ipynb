{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#LGG and HGG tumor classification\n",
        "in this notebook, dataset of BraTS-19 and 18 was taken for classification of HGG and LGG tumors. The dataset has been splitted into training and validation. A function has been written to split data into training and validation, in addition, the dataset has been labeled. HGG=1, and LGG=0\n",
        "then at end end counting entries function has been written to count entries of each components within training and validation. Finally, both dataset 19, and 18 are merged together to make a larger set for training and validation. Training set has almost 80% data and validation set has more and less 20% of total data."
      ],
      "metadata": {
        "id": "RHjRg80MzeP5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXievGujSeF6",
        "outputId": "56c93bfd-ee98-412a-b0e4-c043dad4f59d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# importing necessary packages\n",
        "import os\n",
        "import sys\n",
        "import glob\n",
        "from google.colab import drive\n",
        "import random\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# writing custom function to prepare our dataset\n",
        "def preprocess_split_data(data_path, seed=23):\n",
        "  ''' preprocess data in data_path folder and split HGG and LGG files except seg.nii.gz\n",
        "      take equal number of files from both folder and put it in LGG and HGG files\n",
        "      data_path: path to data folder\n",
        "      return\n",
        "      training_data, and validation_data, and data in a dictionary for training'''\n",
        "  random.seed(seed)\n",
        "  LGG_path = os.path.join(data_path, 'LGG') \n",
        "  HGG_path = os.path.join(data_path, 'HGG')\n",
        "  if len(os.listdir(HGG_path)) > len(os.listdir(LGG_path)):\n",
        "    HGG_folders = os.listdir(HGG_path)\n",
        "    random.shuffle(HGG_folders)\n",
        "    HGG_folders = HGG_folders[:len(os.listdir(LGG_path))]\n",
        "  LGG_folders = os.listdir(LGG_path)\n",
        "  random.shuffle(LGG_folders)\n",
        "  if len(LGG_folders) == len(HGG_folders):\n",
        "    print('Both folders have now equal length')\n",
        "    lgg_folders_paths = []\n",
        "    hgg_folders_paths = []\n",
        "    for folder in LGG_folders:\n",
        "      folder_path = os.path.join(LGG_path, folder)\n",
        "      lgg_folders_paths.append(folder_path)\n",
        "    for folder in HGG_folders:\n",
        "      folder_path = os.path.join(HGG_path, folder)\n",
        "      hgg_folders_paths.append(folder_path)\n",
        "  lgg_files = []\n",
        "  hgg_files = []\n",
        "  for i in range(len(lgg_folders_paths)):\n",
        "    files = sorted(glob.glob(os.path.join(lgg_folders_paths[i], '*.nii.gz')))\n",
        "    lgg_files.append(files)\n",
        "  for j in range(len(hgg_folders_paths)):\n",
        "    files = sorted(glob.glob(os.path.join(hgg_folders_paths[j], '*.nii.gz')))\n",
        "    hgg_files.append(files)\n",
        "  LGG_files = []\n",
        "  HGG_files = []\n",
        "  for i in range(len(lgg_files)):\n",
        "    for j in range(5):\n",
        "      l_fils = lgg_files[i][j]\n",
        "      LGG_files.append(l_fils)\n",
        "  for file in LGG_files:\n",
        "    if 'seg.nii.gz' in file:\n",
        "      LGG_files.remove(file)\n",
        "    else:\n",
        "      pass\n",
        "  for i in range(len(hgg_files)):\n",
        "    for j in range(5):\n",
        "      h_fils = hgg_files[i][j]\n",
        "      HGG_files.append(h_fils)\n",
        "  for file in HGG_files:\n",
        "    if 'seg.nii.gz' in file:\n",
        "      HGG_files.remove(file)\n",
        "    else:\n",
        "      pass\n",
        "  data_paths = HGG_files + LGG_files\n",
        "  random.shuffle(data_paths)\n",
        "  lbl = 1 \n",
        "  dataset_paths = [{'image': img, 'label':lbl} for img in data_paths]\n",
        "  for index in range(len(dataset_paths)):\n",
        "    if 'HGG' in dataset_paths[index]['image']:\n",
        "        dataset_paths[index]['label']=1\n",
        "    else:\n",
        "        dataset_paths[index]['label']=0\n",
        "  train_size = 0.8\n",
        "  train_data = dataset_paths[:int(len(dataset_paths)*train_size)]\n",
        "  val_data = dataset_paths[int(len(dataset_paths)*train_size):]\n",
        "  return train_data, val_data, dataset_paths\n",
        "        "
      ],
      "metadata": {
        "id": "3ORvgRZZSklk"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {
        "id": "oTxSC3hCEjOo"
      },
      "outputs": [],
      "source": [
        "data_path = \"/gdrive/MyDrive/Medical Dataset/Brats'18'\"\n",
        "seed = 111"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_entries(data):\n",
        "  count_flair=0\n",
        "  count_t1 =0\n",
        "  count_t1ce =0\n",
        "  count_t2 =0\n",
        "  for file in data:\n",
        "    if 'flair.nii.gz' in file['image']:\n",
        "      count_flair+=1\n",
        "    elif 't1ce.nii.gz' in file['image']:\n",
        "      count_t1ce+=1\n",
        "    elif 't1.nii.gz' in file['image']:\n",
        "      count_t1 +=1\n",
        "    else:\n",
        "      count_t2+=1\n",
        "  LGG_count=0\n",
        "  HGG_count=0\n",
        "  for file in data:\n",
        "    if 'LGG' in file['image']:\n",
        "      LGG_count+=1\n",
        "    else:\n",
        "      HGG_count+=1\n",
        "  return (LGG_count, HGG_count, count_flair, count_t1, count_t2, count_t1ce)"
      ],
      "metadata": {
        "id": "MphQBXrilDZQ"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path1 = '/gdrive/MyDrive/Medical Dataset/MICCAI_BraTS_2019_Data_Training'"
      ],
      "metadata": {
        "id": "F5nKML0TriJe"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed1= 222\n"
      ],
      "metadata": {
        "id": "MR2MGAoNtPdF"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ready_all_data(data_path, data_path1):\n",
        "  ''' this funtion ready all the dataset into training and validation sets for trainiing\n",
        "      data_path: data_path of 2019 Brats dataset\n",
        "      data_path1: data path of 2018 Brats dataset\n",
        "      return \n",
        "      training_data: shuffled training data (80%)\n",
        "      validation_data: shuffled validatoin data (20%)\n",
        "      '''\n",
        "  train, val, data = preprocess_split_data(data_path, seed)\n",
        "  train1, val1, data1 = preprocess_split_data(data_path1, seed1)\n",
        "  training_data = train + train1\n",
        "  validation_data = val + val1\n",
        "  all_data = data + data1\n",
        "  random.seed(11)\n",
        "  random.shuffle(training_data)\n",
        "  random.shuffle(validation_data)\n",
        "  random.shuffle(all_data)\n",
        "  return (training_data, validation_data, all_data)\n",
        "\n"
      ],
      "metadata": {
        "id": "LO-5nVt94CIc"
      },
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data, validation_data, _ = ready_all_data(data_path, data_path1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2zdJcDR4EeD",
        "outputId": "d80f82fc-3942-4897-b85f-b4fb5202dd74"
      },
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Both folders have now equal length\n",
            "Both folders have now equal length\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(training_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46_ebn3j57nN",
        "outputId": "ec50f0f9-b5cf-4946-de9f-ba5af465ec40"
      },
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "966"
            ]
          },
          "metadata": {},
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LGG_count, HGG_count, count_flair, count_t1, count_t2, count_t1ce = count_entries(validation_data)"
      ],
      "metadata": {
        "id": "ltYOz5Sd5-Zc"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'counting differnting classes entry in validation data with seed:{seed}')\n",
        "print(f'number of flairs: {count_flair}')\n",
        "print(f'number of t1: {count_t1}')\n",
        "print(f'number of t2: {count_t2}')\n",
        "print(f'number of t1ce: {count_t1ce}')\n",
        "print(f'LGG count: {LGG_count}')\n",
        "print(f'HGG count: {HGG_count}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgyBaDb_6BUH",
        "outputId": "beba87ed-8427-47cd-d81f-ceb389086155"
      },
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "counting differnting classes entry in validation data with seed:111\n",
            "number of flairs: 61\n",
            "number of t1: 55\n",
            "number of t2: 67\n",
            "number of t1ce: 59\n",
            "LGG count: 121\n",
            "HGG count: 121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jxdH7cYv6W_R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}