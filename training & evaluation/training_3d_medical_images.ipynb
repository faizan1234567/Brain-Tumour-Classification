{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training_3d_medical_imeges.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0eQ9JbgtGgrM"
      },
      "outputs": [],
      "source": [
        "!pip install -qU \"monai[ignite, nibabel, torchvision, tqdm]==0.6.0\"\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install import-ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEiR244hKIc4",
        "outputId": "6537ca2d-8015-44d7-c404-a35aa752cf78"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: import-ipynb in /usr/local/lib/python3.7/dist-packages (0.1.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWFcff-lJRC9",
        "outputId": "adabcae5-923c-4175-a216-ad7d4feead8f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading packages\n",
        "import random\n",
        "import logging\n",
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import nibabel as nib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision import models, datasets\n",
        "\n",
        "from monai.utils import first\n",
        "from monai.data import decollate_batch\n",
        "from monai.metrics import ROCAUCMetric\n",
        "from monai.transforms import (Activations,\n",
        "                              AddChanneld, \n",
        "                              AsDiscrete, \n",
        "                              Compose, \n",
        "                              LoadImaged, \n",
        "                              RandRotate90d, \n",
        "                              Resized, \n",
        "                              ScaleIntensityd,\n",
        "                              RandAffined,\n",
        "                              RandRotated,\n",
        "                              RandGaussianNoised,\n",
        "                              EnsureTyped,\n",
        "                              EnsureType,\n",
        "                              ToTensord)\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "# import datetime\n",
        "# from tensorflow import summary\n",
        "# import tensorflow as tf\n",
        "from monai.metrics import get_confusion_matrix, ConfusionMatrixMetric\n",
        "import time\n",
        "import import_ipynb\n",
        "torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "pcSWU37bIAB2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/gdrive/MyDrive/Colab Notebooks'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLgFFkIBIF7p",
        "outputId": "9e1c308e-1f3d-4841-cab3-2526f8fae70e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/MyDrive/Colab Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def transfoms_augmentation():\n",
        "  ''' transform and augment images\n",
        "  return:\n",
        "         transformed and augmentated images'''\n",
        "  data_transforms = {\n",
        "        'train':    Compose([\n",
        "                     LoadImaged(keys = [\"image\"]),\n",
        "                     AddChanneld(keys = [\"image\"]),\n",
        "                     ScaleIntensityd(keys = [\"image\"]),\n",
        "                     Resized(keys = [\"image\"], spatial_size = (128, 128, 128)),\n",
        "                     RandAffined(keys = [\"image\"], prob=0.5, translate_range = 10),\n",
        "                     RandRotate90d(keys=[\"image\"], prob=0.8, spatial_axes=[0, 2]),\n",
        "                     EnsureTyped(keys=[\"image\"]),\n",
        "                    #  ToTensord(keys = [\"image\"])\n",
        "                     ]),\n",
        "        'val':      Compose([\n",
        "                     LoadImaged(keys=[\"image\"]),\n",
        "                     AddChanneld(keys=[\"image\"]),\n",
        "                     ScaleIntensityd(keys=[\"image\"]),\n",
        "                     Resized(keys=[\"image\"], spatial_size=(128, 128, 128)),\n",
        "                     EnsureTyped(keys=[\"image\"]),\n",
        "                    #  ToTensord(keys = [\"image\"])\n",
        "                      ])\n",
        "                     }\n",
        "  return data_transforms"
      ],
      "metadata": {
        "id": "5hF1oJy01Gmp"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import data_preparation\n"
      ],
      "metadata": {
        "id": "UkPsrRTGKZes"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = data_preparation.data_path\n",
        "data_path1 = data_preparation.data_path1"
      ],
      "metadata": {
        "id": "TAerijc_Kwz_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare and load all training and validation data\n",
        "training_data, validation_data, data = data_preparation.ready_all_data(data_path, data_path1) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKkh4fgbLBK7",
        "outputId": "e09db72f-4121-4a91-d7a3-40c3c4056de3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Both folders have now equal length\n",
            "Both folders have now equal length\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#length of dataset\n",
        "print(f'length of training data: {len(training_data)}')\n",
        "print(f'length of validation data: {len(validation_data)}')\n",
        "print(f'length of total data: {len(data)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEnOs9aBLCiq",
        "outputId": "d3629efc-177b-4d0d-b25d-3a9c3c1b27eb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of training data: 966\n",
            "length of validation data: 242\n",
            "length of total data: 1208\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#inspecting data\n",
        "train_index = np.random.randint(len(training_data))\n",
        "print(f\"training file at {train_index}:, image: {training_data[train_index]['image']} , label: {training_data[train_index]['label']}\")\n",
        "val_index = np.random.randint(len(validation_data))\n",
        "print(f\"validation file at {val_index}:, image: {validation_data[val_index]['image']}, label: {validation_data[val_index]['label']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiPwK7OTL4Ea",
        "outputId": "2e1b22a1-6a84-4e18-c317-b79bd7d0207e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training file at 530:, image: /gdrive/MyDrive/Medical Dataset/MICCAI_BraTS_2019_Data_Training/LGG/BraTS19_TCIA13_654_1/BraTS19_TCIA13_654_1_t1ce.nii.gz , label: 0\n",
            "validation file at 67:, image: /gdrive/MyDrive/Medical Dataset/MICCAI_BraTS_2019_Data_Training/HGG/BraTS19_TCIA02_491_1/BraTS19_TCIA02_491_1_flair.nii.gz, label: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#checking files in dataset\n",
        "LGG_count, HGG_count, count_flair, count_t1, count_t2, count_t1ce = data_preparation.count_entries(validation_data)\n",
        "print(f'counting differnting classes entry in validation data with seed:{data_preparation.seed1}')\n",
        "print(f'number of flairs: {count_flair}')\n",
        "print(f'number of t1: {count_t1}')\n",
        "print(f'number of t2: {count_t2}')\n",
        "print(f'number of t1ce: {count_t1ce}')\n",
        "print(f'LGG count: {LGG_count}')\n",
        "print(f'HGG count: {HGG_count}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkMATPA1MCIp",
        "outputId": "53c4a754-6a78-480a-b1db-7b2fb98956a4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "counting differnting classes entry in validation data with seed:222\n",
            "number of flairs: 61\n",
            "number of t1: 55\n",
            "number of t2: 67\n",
            "number of t1ce: 59\n",
            "LGG count: 121\n",
            "HGG count: 121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LGG_count, HGG_count, count_flair, count_t1, count_t2, count_t1ce = data_preparation.count_entries(training_data)\n",
        "print(f'counting differnting classes entry in training data with seed:{data_preparation.seed}')\n",
        "print(f'number of flairs: {count_flair}')\n",
        "print(f'number of t1: {count_t1}')\n",
        "print(f'number of t2: {count_t2}')\n",
        "print(f'number of t1ce: {count_t1ce}')\n",
        "print(f'LGG count: {LGG_count}')\n",
        "print(f'HGG count: {HGG_count}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrnKmntxN8SL",
        "outputId": "95493ccc-a07f-419f-a76f-609b1b690e4c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "counting differnting classes entry in training data with seed:111\n",
            "number of flairs: 241\n",
            "number of t1: 247\n",
            "number of t2: 235\n",
            "number of t1ce: 243\n",
            "LGG count: 483\n",
            "HGG count: 483\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "post_pred = Compose([EnsureType(), Activations(softmax=True)])\n",
        "post_label = Compose([EnsureType(), AsDiscrete(to_onehot=2)])"
      ],
      "metadata": {
        "id": "7XTlmSbGOMa4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_transforms = transforms_augmentation()\n",
        "training_transforms = data_transforms['train']\n",
        "validation_transforms = data_transforms['val']\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "5qpCcJe8RKPi",
        "outputId": "5f8a5bb2-c218-4444-9b38-87b297549dc4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-eec9f622fc11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_transforms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms_augmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtraining_transforms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_transforms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvalidation_transforms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_transforms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check_ds = monai.data.Dataset(data=training_data, transform=training_transforms)\n",
        "check_loader = DataLoader(check_ds, batch_size=8, num_workers=1, pin_memory=torch.cuda.is_available())\n",
        "check_data = monai.utils.misc.first(check_loader)\n",
        "print(check_data[\"image\"].shape, check_data[\"label\"].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPpjySe0Rho7",
        "outputId": "a7f8e050-e26e-4fda-c1cd-52028bf2727d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 1, 128, 128, 128]) torch.Size([8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a training data loader\n",
        "train_ds = monai.data.Dataset(data=training_data, transform=training_transforms)\n",
        "train_loader = DataLoader(train_ds, batch_size=6, shuffle=True, num_workers=1, pin_memory=torch.cuda.is_available(), drop_last=False)\n",
        "\n",
        "    # create a validation data loader\n",
        "val_ds = monai.data.Dataset(data=validation_data, transform=validation_transforms)\n",
        "val_loader = DataLoader(val_ds, batch_size=6, num_workers=1, pin_memory=torch.cuda.is_available(), drop_last=False)"
      ],
      "metadata": {
        "id": "p18bNYmNSdTE"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, loss_fn, train_loader, val_loader, auc_metric, num_epochs=50):\n",
        "  '''train the model on brain tumour dataset\n",
        "  model: a deep leanring model\n",
        "  optimizer: select a optimizer eg. Adam\n",
        "  loss_fn: loss function \n",
        "  train_loader: load training data in batches\n",
        "  val_loader: load validation data in batches\n",
        "  '''\n",
        "  val_interval = 2\n",
        "  best_metric = -1\n",
        "  best_metric_epoch = -1\n",
        "  writer = SummaryWriter()\n",
        "  for epoch in range(num_epochs):\n",
        "    print('-'*45)\n",
        "    epoch_loss = 0\n",
        "    num_corrects = 0\n",
        "    step = 0\n",
        "    print(f'epoch: {epoch+1}/{num_epochs}')\n",
        "    model.train()\n",
        "    for data in train_loader:\n",
        "      images, labels = data[\"image\"].to(device), data[\"label\"].to(device)\n",
        "      outputs = model(images)\n",
        "      loss = loss_fn(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "      prediction = torch.argmax(outputs, dim=1)\n",
        "      num_corrects += torch.eq(prediction, labels).sum().float()\n",
        "      epoch_loss += loss.item()\n",
        "      epoch_len = len(train_ds) // train_loader.batch_size\n",
        "      print(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\")\n",
        "      writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n",
        "    epoch_loss/=step\n",
        "    epoch_acc = num_corrects/(len(train_ds)-(len(train_ds) - epoch_len * train_loader.batch_size))\n",
        "    print(f'epoch training accuracy: {epoch_acc}', end= \" \")\n",
        "    print(f\" epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
        "    if (epoch + 1) % val_interval == 0:\n",
        "      model.eval()\n",
        "      with torch.no_grad():\n",
        "        y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
        "        y = torch.tensor([], dtype=torch.long, device=device)\n",
        "        for val_data in val_loader:\n",
        "          val_images, val_labels = val_data[\"image\"].to(device), val_data[\"label\"].to(device)\n",
        "          y_pred = torch.cat([y_pred, model(val_images)], dim=0)\n",
        "          y = torch.cat([y, val_labels], dim=0)\n",
        "        acc_value = torch.eq(y_pred.argmax(dim=1), y)\n",
        "        acc_metric = acc_value.sum().item() / len(acc_value)\n",
        "        y_onehot = [post_label(i) for i in decollate_batch(y)]\n",
        "        y_pred_act = [post_pred(i) for i in decollate_batch(y_pred)]\n",
        "        auc_metric(y_pred_act, y_onehot)\n",
        "        auc_result = auc_metric.aggregate()\n",
        "        auc_metric.reset()\n",
        "        del y_pred_act, y_onehot\n",
        "        if acc_metric > best_metric:\n",
        "          best_metric = acc_metric\n",
        "          best_metric_epoch = epoch + 1\n",
        "          torch.save(model.state_dict(), \"best_metric_model_classification3d_dict.pth\")\n",
        "          print(\"saved new best metric model\")\n",
        "        print(\"current epoch: {} current accuracy: {:.4f} current AUC: {:.4f} best accuracy: {:.4f} at epoch {}\".format(\n",
        "                        epoch + 1, acc_metric, auc_result, best_metric, best_metric_epoch))\n",
        "        writer.add_scalar(\"val_accuracy\", acc_metric, epoch + 1)\n",
        "  print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
        "  writer.close()"
      ],
      "metadata": {
        "id": "ruXP-7GwgN0O"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = monai.networks.nets.DenseNet121(spatial_dims=3, in_channels=1, out_channels=2).to(device)\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), 1e-5)\n",
        "auc_metric = ROCAUCMetric()"
      ],
      "metadata": {
        "id": "QAf9M9PJgemg"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model, optimizer, loss_function, train_loader, val_loader, auc_metric, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "9V5hDimprJ1h",
        "outputId": "f3ff7094-3d5e-46dd-d32f-10f7861f87f9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0aa4764af39a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sikAl6tHrPFg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}